import streamlit as st
import requests
import json
import numpy as np
import os # íŒŒì¼ ì €ì¥ì„ ìœ„í•´
import re 
import update_logic 

API_ENDPOINT_URL = "https://j0bzidcs1d.execute-api.us-east-1.amazonaws.com/chat" 

# 2. (ê°€ì¥ ì¤‘ìš”!) user_1_taste_vector.json íŒŒì¼ì˜ ì •í™•í•œ ê²½ë¡œ ì„¤ì •
try:
    BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
    USER_VECTOR_PATH = os.path.join(BASE_DIR, "data", "user", "user_1_taste_vector.json") 
    
    if not os.path.exists(USER_VECTOR_PATH):
        print(f"Warning: USER_VECTOR_PATH not found at {USER_VECTOR_PATH}")

except NameError:
    BASE_DIR = os.path.abspath(".")
    USER_VECTOR_PATH = os.path.join(BASE_DIR, "data", "user", "user_1_taste_vector.json")
    print(f"Warning: __file__ not defined. Using relative path: {USER_VECTOR_PATH}")


# --- í—¬í¼ í•¨ìˆ˜ (ë²¡í„° ê²€ìƒ‰ ë° ì €ì¥) ---

def find_product_matches_by_name(product_name, products_data):
    """
    st.session_state.productsì—ì„œ 'product_name'ì´ í¬í•¨ëœ ëª¨ë“  ì œí’ˆì˜ 'name' ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜
    """
    if not products_data:
        return []
    
    matches = []
    product_name_lower = product_name.lower()
    
    for product in products_data:
        product_db_name = product.get('name', '').lower()
        if product_name_lower in product_db_name:
            matches.append(product.get('name')) # ì „ì²´ ì´ë¦„ì„ ë°˜í™˜
    return matches

def find_product_vector_by_exact_name(product_name, products_data):
    """
    st.session_state.productsì—ì„œ 'product_name'ê³¼ *ì •í™•íˆ* ì¼ì¹˜í•˜ëŠ” ì œí’ˆì˜ ë²¡í„°ë¥¼ ë°˜í™˜
    """
    if not products_data:
        return None
    
    product_name_lower = product_name.lower() # ë¹„êµë¥¼ ìœ„í•´ ì†Œë¬¸ìë¡œ
    
    for product in products_data:
        product_db_name = product.get('name', '').lower()
        if product_name_lower == product_db_name: # ì •í™•íˆ ì¼ì¹˜(==)í•˜ëŠ”ì§€ í™•ì¸
            return product.get('product_vector') 
    return None

def save_user_vector(user_vector):
    """
    ì—…ë°ì´íŠ¸ëœ ìœ ì € ë²¡í„°ë¥¼ user_1_taste_vector.json íŒŒì¼ì— ë®ì–´ì“°ëŠ” í•¨ìˆ˜
    {"user_id": ..., "user_taste_vector": ...} êµ¬ì¡°ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.
    """
    try:
        if isinstance(user_vector, np.ndarray):
            user_vector = user_vector.tolist()
            
        data_to_save = {
            "user_id": "user_1", 
            "user_taste_vector": user_vector 
        }
            
        with open(USER_VECTOR_PATH, 'w', encoding='utf-8') as f:
            json.dump(data_to_save, f, ensure_ascii=False, indent=4)
        print(f"User vector successfully saved to {USER_VECTOR_PATH}")
    except Exception as e:
        print(f"Error saving user vector: {e}")
        st.error(f"ë²¡í„°ë¥¼ íŒŒì¼ì— ì €ì¥í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. (ê²½ë¡œ: {USER_VECTOR_PATH})")


# --- ë©”ì¸ ì±—ë´‡ ì‹¤í–‰ í•¨ìˆ˜ ---

def run_chatbot():
    
    # ìŠ¤íƒ€ì¼ë§ ì½”ë“œ (ì „ì²´ í¬í•¨)
    st.markdown("""
        <style>
        /* ì±—ë´‡ íƒ€ì´í‹€ */
        .chatbot-title {
            font-size: 36px;
            font-weight: bold;
            color: #20314e;
            text-align: center;
            margin-bottom: 10px;
        }
        
        /* ì±— ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆ */
        .stChatMessage {
            background-color: #f8f9fa;
            border-radius: 15px;
            padding: 15px;
            margin: 10px 0;
        }
        
        /* ì‚¬ìš©ì ë©”ì‹œì§€ */
        [data-testid="stChatMessageContent"] {
            background-color: #ffffff;
            border-left: 4px solid #fe9600;
            padding: 12px;
            border-radius: 10px;
        }
        
        /* AI ë©”ì‹œì§€ */
        .stChatMessage[data-testid="assistant"] {
            background-color: #f0f4f8;
            border-left: 4px solid #20314e;
        }
        
        /* ì±„íŒ… ì…ë ¥ì°½ */
        .stChatInput > div {
            border: 2px solid #20314e;
            border-radius: 25px;
        }
        
        .stChatInput > div:focus-within {
            border-color: #fe9600;
            box-shadow: 0 0 0 2px rgba(254, 150, 0, 0.2);
        }
        
        /* ì „ì†¡ ë²„íŠ¼ */
        .stChatInput button {
            background-color: #fe9600 !important;
            color: white !important;
            border-radius: 50%;
        }
        
        .stChatInput button:hover {
            background-color: #e58700 !important;
        }
        
        /* ìŠ¤í¬ë¡¤ë°” ì»¤ìŠ¤í„°ë§ˆì´ì§• */
        ::-webkit-scrollbar {
            width: 8px;
        }
        
        ::-webkit-scrollbar-track {
            background: #f1f1f1;
        }
        
        ::-webkit-scrollbar-thumb {
            background: #20314e;
            border-radius: 4px;
        }
        
        ::-webkit-scrollbar-thumb:hover {
            background: #fe9600;
        }
        
        /* ì±„íŒ… ì˜ì—­ */
        .chat-container {
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
        }
        </style>
    """, unsafe_allow_html=True)
    
    # ì±—ë´‡ í˜ì´ì§€ íƒ€ì´í‹€
    st.markdown('<div class="chatbot-title">ğŸ¤– ì±—ë´‡</div>', unsafe_allow_html=True)
    st.markdown('<p style="text-align: center; color: #5D6D7E; margin-bottom: 30px;">ì œê°€ ì¶”ì²œí•œ ë¼ë©´ì€ ì–´ë– ì…¨ë‚˜ìš”?! í›„ê¸°ë¥¼ ë‚¨ê²¨ì£¼ì‹œë©´ ì…ë§›ì— ë°˜ì˜í• ê²Œìš”.</p>', unsafe_allow_html=True)

    # --- 4. ì±—ë´‡ ìƒíƒœ ê´€ë¦¬ (ë™ì¼) ---
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "chat_mode" not in st.session_state:
        st.session_state.chat_mode = "normal"
    if "review_product_context" not in st.session_state:
        st.session_state.review_product_context = {"name": None, "vector": None}
    # --- ---------------------------

    # 5. ì±„íŒ… UI (ë™ì¼)
    st.markdown('<div class="chat-container">', unsafe_allow_html=True)
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    st.markdown('</div>', unsafe_allow_html=True)

    # 6. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if user_input := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ëŠ” í•­ìƒ UIì— ì¶”ê°€í•˜ê³  í‘œì‹œ
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        # -----------------------------------------------
        # 6-A. "ìƒí’ˆëª…"ì„ ê¸°ë‹¤ë¦¬ë˜ ìƒíƒœì¼ ë•Œ (ë™ì¼)
        # -----------------------------------------------
        if st.session_state.chat_mode == "awaiting_product_name":
            if "ì·¨ì†Œ" in user_input.lower():
                st.session_state.chat_mode = "normal"
                response = "ì•Œê² ìŠµë‹ˆë‹¤. í›„ê¸° ì‘ì„±ì„ ì·¨ì†Œí•©ë‹ˆë‹¤."
                st.session_state.messages.append({"role": "assistant", "content": response})
                with st.chat_message("assistant"):
                    st.markdown(response)
                st.rerun() 
                return 

            product_name_input = user_input 
            product_vector = None
            product_name_found = None
            response = None 

            product_vector = find_product_vector_by_exact_name(product_name_input, st.session_state.get("products", []))
            
            if product_vector:
                product_name_found = product_name_input
            else:
                partial_matches = find_product_matches_by_name(product_name_input, st.session_state.get("products", []))
                
                if len(partial_matches) == 1:
                    product_name_found = partial_matches[0]
                    product_vector = find_product_vector_by_exact_name(product_name_found, st.session_state.get("products", []))
                
                elif len(partial_matches) > 1:
                    response = f"'{product_name_input}'ê³¼(ì™€) ì¼ì¹˜í•˜ëŠ” ìƒí’ˆì´ ì—¬ëŸ¬ ê°œ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ ëª©ë¡ì—ì„œ ì •í™•í•œ ìƒí’ˆëª…ì„ ë³µì‚¬/ì…ë ¥í•´ì£¼ì„¸ìš”.\n\n"
                    for name in partial_matches[:10]:
                        response += f"- {name}\n"
                    response += "\n\n(í›„ê¸° ì‘ì„±ì„ ê·¸ë§Œë‘ë ¤ë©´ 'ì·¨ì†Œ'ë¼ê³  ì…ë ¥í•˜ì„¸ìš”)"
                
                else:
                    response = f"'{product_name_input}' ìƒí’ˆì„ ì°¾ì§€ ëª»í–ˆì–´ìš”. ì •í™•í•œ ìƒí’ˆëª…ì„ ë‹¤ì‹œ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”? (í›„ê¸° ì‘ì„±ì„ ê·¸ë§Œë‘ë ¤ë©´ 'ì·¨ì†Œ'ë¼ê³  ì…ë ¥í•˜ì„¸ìš”)"

            if product_name_found and product_vector:
                st.session_state.review_product_context = {"name": product_name_found, "vector": product_vector}
                st.session_state.chat_mode = "awaiting_review_text" # ë‹¤ìŒ ìƒíƒœë¡œ
                response = f"'{product_name_found}' ìƒí’ˆìœ¼ë¡œ í›„ê¸°ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤. ë§›ì´ ì–´ë– ì…¨ë‚˜ìš”? (ì˜ˆ: 'ì§°ì–´ìš”', 'ë§¤ì½¤í•˜ê³  ì¢‹ì•˜ì–´ìš”.')"
            elif product_name_found and not product_vector:
                response = f"'{product_name_found}' ìƒí’ˆì€ ì°¾ì•˜ì§€ë§Œ ë²¡í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. DBë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

            st.session_state.messages.append({"role": "assistant", "content": response})
            with st.chat_message("assistant"):
                st.markdown(response)

        # -----------------------------------------------
        # 6-B. "í›„ê¸° í…ìŠ¤íŠ¸"ë¥¼ ê¸°ë‹¤ë¦¬ë˜ ìƒíƒœì¼ ë•Œ (!!! ë‹˜ì˜ ìš”ì²­ëŒ€ë¡œ ìˆ˜ì • !!!)
        # -----------------------------------------------
        elif st.session_state.chat_mode == "awaiting_review_text":
            review_text = user_input
            product_name = st.session_state.review_product_context["name"]
            product_vector = st.session_state.review_product_context["vector"]
            
            with st.chat_message("assistant"):
                with st.spinner(f"í›„ê¸° ë¶„ì„ ë° ì…ë§› ë°˜ì˜ ì¤‘..."):
                    
                    user_vector = st.session_state.get("user_vector") 

                    if not user_vector or not product_vector:
                        st.error("ì…ë§› ë²¡í„° ë˜ëŠ” ìƒí’ˆ ë²¡í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'ë‚´ ì…ë§› ì°¾ê¸°'ë¥¼ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.")
                        st.session_state.chat_mode = "normal"
                        return

                    # 1. (!!!) Bedrockì— ë³´ë‚¼ 'ê°€ë²¼ìš´ ê¸/ë¶€ì •' í”„ë¡¬í”„íŠ¸ ìƒì„±
                    # (ë²¡í„° 2ê°œë¥¼ ë³´ë‚´ì§€ ì•ŠìŠµë‹ˆë‹¤!)
                    sentiment_prompt = f"""
                    ë‹¤ìŒ ìŒì‹ í›„ê¸°ë¥¼ ë¶„ì„í•˜ê³ , ì´ í›„ê¸°ê°€ 'positive'(ê¸ì •), 'negative'(ë¶€ì •), 'neutral'(ì¤‘ë¦½) ì¤‘ ë¬´ì—‡ì¸ì§€ ì˜ì–´ ë‹¨ì–´ í•˜ë‚˜ë¡œë§Œ ëŒ€ë‹µí•´.
                    
                    í›„ê¸°: "{review_text}"
                    
                    ë‹µë³€ (positive, negative, neutral ì¤‘ í•˜ë‚˜):
                    """
                    
                    bot_response = ""
                    try:
                        # 2. API Gateway í˜¸ì¶œ (ê°€ë²¼ìš´ ìš”ì²­ -> 503/ì°¨ì› ë¶ˆì¼ì¹˜ ì˜¤ë¥˜ í•´ê²°!)
                        response = requests.post(
                            API_ENDPOINT_URL, 
                            data=json.dumps({"prompt": sentiment_prompt}),
                            headers={"Content-Type": "application/json"}
                        )
                        
                        if response.status_code == 200:
                            response_body_text = response.json().get("response", "neutral")
                            
                            # 3. AI ì‘ë‹µì—ì„œ ê¸/ë¶€ì • ì¶”ì¶œ (by update_logic.py)
                            sentiment = update_logic.get_sentiment(response_body_text)
                            
                            # 4. ë²¡í„° ìˆ˜í•™ (by update_logic.py)
                            # (!!!) ëª¨ë“  ê³„ì‚°ì€ Lambdaê°€ ì•„ë‹Œ ë¡œì»¬ì—ì„œ ì¼ì–´ë‚¨
                            new_vector = update_logic.run_update(user_vector, product_vector, sentiment)

                            # 5. ë¡œì»¬ ì„¸ì…˜ ë° íŒŒì¼ ì €ì¥
                            if isinstance(new_vector, list) and len(new_vector) == len(user_vector):
                                st.session_state.user_vector = new_vector
                                save_user_vector(new_vector) 
                                bot_response = "ì†Œì¤‘í•œ í›„ê¸° ê°ì‚¬í•©ë‹ˆë‹¤! ë‹˜ì˜ ì…ë§› ì •ë³´ì— ë°˜ì˜í–ˆì–´ìš”."
                            else:
                                bot_response = "ë²¡í„° ê³„ì‚° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                        
                        else:
                            bot_response = f"ì£„ì†¡í•©ë‹ˆë‹¤, AI ì„œë²„ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. (ì½”ë“œ: {response.status_code})\nì˜¤ë¥˜: {response.text}"
                    
                    except Exception as e:
                        bot_response = f"API í˜¸ì¶œ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}"
                    
                    st.markdown(bot_response)
                    st.session_state.messages.append({"role": "assistant", "content": bot_response})
                    
                    # ìƒíƒœ ì´ˆê¸°í™”
                    st.session_state.chat_mode = "normal" 
                    st.session_state.review_product_context = {"name": None, "vector": None}

        # -----------------------------------------------
        # 6-C. "ì¼ë°˜ ëŒ€í™”" ìƒíƒœì¼ ë•Œ (ë™ì¼)
        # -----------------------------------------------
        else: # st.session_state.chat_mode == "normal"
            
            # "í›„ê¸°" í‚¤ì›Œë“œ ê°ì§€
            if "í›„ê¸°" in user_input or "ë¦¬ë·°" in user_input or "ë¨¹ì–´ë´¤" in user_input:
                if not st.session_state.get("user_vector"):
                    response = "í›„ê¸°ë¥¼ ë‚¨ê¸°ì‹œë ¤ë©´ ë¨¼ì € 'ë‚´ ì…ë§› ì°¾ê¸°' íƒ­ì—ì„œ ì„¤ë¬¸ì¡°ì‚¬ë¥¼ ì™„ë£Œí•´ì£¼ì„¸ìš”!"
                    st.session_state.messages.append({"role": "assistant", "content": response})
                    with st.chat_message("assistant"):
                        st.markdown(response)
                else:
                    st.session_state.chat_mode = "awaiting_product_name" # ìƒíƒœ ë³€ê²½
                    response = "ì¢‹ìŠµë‹ˆë‹¤! ì–´ë–¤ ìƒí’ˆì— ëŒ€í•œ í›„ê¸°ì¸ê°€ìš”? ìƒí’ˆëª…ì„ ì •í™•íˆ ì•Œë ¤ì£¼ì„¸ìš”."
                    st.session_state.messages.append({"role": "assistant", "content": response})
                    with st.chat_message("assistant"):
                        st.markdown(response)
            
            elif "ì·¨ì†Œ" in user_input.lower():
                   st.session_state.chat_mode = "normal" # ìƒíƒœ ì´ˆê¸°í™”
                   response = "ì•Œê² ìŠµë‹ˆë‹¤. ì–¸ì œë“  ë‹¤ì‹œ ë¶ˆëŸ¬ì£¼ì„¸ìš”."
                   st.session_state.messages.append({"role": "assistant", "content": response})
                   with st.chat_message("assistant"):
                        st.markdown(response)

            # ì¼ë°˜ ëŒ€í™” (ê¸°ì¡´ API í˜¸ì¶œ)
            else:
                with st.chat_message("assistant"):
                    with st.spinner("AIê°€ ìƒê° ì¤‘ì…ë‹ˆë‹¤..."):
                        try:
                            response = requests.post(
                                API_ENDPOINT_URL, 
                                data=json.dumps({"prompt": user_input}),
                                headers={"Content-Type": "application/json"}
                            )
                            if response.status_code == 200:
                                bot_response = response.json().get("response", "ì˜¤ë¥˜: ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.")
                            else:
                                bot_response = f"ì£„ì†¡í•©ë‹ˆë‹¤, ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. (ì½”ë“œ: {response.status_code})"
                        except Exception as e:
                            bot_response = f"API í˜¸ì¶œ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}"
                        
                        st.markdown(bot_response)
                st.session_state.messages.append({"role": "assistant", "content": bot_response})

# ì´ íŒŒì¼ì´ ë©”ì¸ìœ¼ë¡œ ì‹¤í–‰ë  ê²½ìš°(í…ŒìŠ¤íŠ¸ìš©)
if __name__ == "__main__":
    
        
    run_chatbot()